{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=21\n",
    "voice = pd.read_csv('voice.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将label转换成0和1，male 1; female 0\n",
    "voice['label'] = voice['label'].apply(lambda x: 1 if x=='male' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr.models import DeepFM, WDL\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat, get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate feature columns\n",
    "features = list(voice.columns)\n",
    "dense_feature = features[:-1]\n",
    "\n",
    "dense_feature_columns = [DenseFeat(feature, dimension=1) for feature in dense_feature]\n",
    "\n",
    "linear_feature = dense_feature_columns\n",
    "deep_feature = dense_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "voice[dense_feature] = ss.fit_transform(voice[dense_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(voice[dense_feature], voice['label'], test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {name: x_train[name].values for name in dense_feature}\n",
    "test_data = {name: x_test[name].values for name in dense_feature}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8325 - acc: 0.5935 - val_loss: 0.6322 - val_acc: 0.6805\n",
      "Epoch 2/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4668 - acc: 0.7908 - val_loss: 0.3781 - val_acc: 0.8698\n",
      "Epoch 3/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3123 - acc: 0.8984 - val_loss: 0.2763 - val_acc: 0.9211\n",
      "Epoch 4/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2324 - acc: 0.9255 - val_loss: 0.2108 - val_acc: 0.9487\n",
      "Epoch 5/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1777 - acc: 0.9433 - val_loss: 0.1645 - val_acc: 0.9546\n",
      "Epoch 6/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1403 - acc: 0.9526 - val_loss: 0.1353 - val_acc: 0.9625\n",
      "Epoch 7/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1179 - acc: 0.9581 - val_loss: 0.1153 - val_acc: 0.9724\n",
      "Epoch 8/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1039 - acc: 0.9660 - val_loss: 0.1026 - val_acc: 0.9744\n",
      "Epoch 9/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0949 - acc: 0.9689 - val_loss: 0.0950 - val_acc: 0.9724\n",
      "Epoch 10/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0918 - acc: 0.9689 - val_loss: 0.0884 - val_acc: 0.9744\n",
      "Epoch 11/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0832 - acc: 0.9729 - val_loss: 0.0832 - val_acc: 0.9744\n",
      "Epoch 12/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0784 - acc: 0.9729 - val_loss: 0.0819 - val_acc: 0.9724\n",
      "Epoch 13/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0762 - acc: 0.9734 - val_loss: 0.0751 - val_acc: 0.9763\n",
      "Epoch 14/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0719 - acc: 0.9753 - val_loss: 0.0726 - val_acc: 0.9763\n",
      "Epoch 15/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0689 - acc: 0.9739 - val_loss: 0.0736 - val_acc: 0.9783\n",
      "Epoch 16/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0677 - acc: 0.9773 - val_loss: 0.0703 - val_acc: 0.9763\n",
      "Epoch 17/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0647 - acc: 0.9793 - val_loss: 0.0691 - val_acc: 0.9783\n",
      "Epoch 18/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0621 - acc: 0.9793 - val_loss: 0.0705 - val_acc: 0.9763\n",
      "Epoch 19/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0632 - acc: 0.9763 - val_loss: 0.0655 - val_acc: 0.9783\n",
      "Epoch 20/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0594 - acc: 0.9793 - val_loss: 0.0680 - val_acc: 0.9763\n",
      "Epoch 21/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0577 - acc: 0.9808 - val_loss: 0.0675 - val_acc: 0.9783\n",
      "Epoch 22/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0557 - acc: 0.9817 - val_loss: 0.0680 - val_acc: 0.9763\n",
      "Epoch 23/110\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0550 - acc: 0.9813 - val_loss: 0.0669 - val_acc: 0.9783\n",
      "Epoch 24/110\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0536 - acc: 0.9808 - val_loss: 0.0673 - val_acc: 0.9744\n",
      "Epoch 25/110\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0519 - acc: 0.9837 - val_loss: 0.0662 - val_acc: 0.9783\n",
      "Epoch 26/110\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0508 - acc: 0.9827 - val_loss: 0.0664 - val_acc: 0.9763\n",
      "Epoch 27/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0491 - acc: 0.9832 - val_loss: 0.0674 - val_acc: 0.9763\n",
      "Epoch 28/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0484 - acc: 0.9847 - val_loss: 0.0687 - val_acc: 0.9763\n",
      "Epoch 29/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0476 - acc: 0.9827 - val_loss: 0.0655 - val_acc: 0.9763\n",
      "Epoch 30/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0462 - acc: 0.9837 - val_loss: 0.0647 - val_acc: 0.9822\n",
      "Epoch 31/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0455 - acc: 0.9837 - val_loss: 0.0664 - val_acc: 0.9803\n",
      "Epoch 32/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0447 - acc: 0.9842 - val_loss: 0.0674 - val_acc: 0.9763\n",
      "Epoch 33/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0442 - acc: 0.9842 - val_loss: 0.0652 - val_acc: 0.9803\n",
      "Epoch 34/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0418 - acc: 0.9852 - val_loss: 0.0683 - val_acc: 0.9744\n",
      "Epoch 35/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0417 - acc: 0.9847 - val_loss: 0.0676 - val_acc: 0.9763\n",
      "Epoch 36/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0413 - acc: 0.9857 - val_loss: 0.0673 - val_acc: 0.9763\n",
      "Epoch 37/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0403 - acc: 0.9857 - val_loss: 0.0703 - val_acc: 0.9763\n",
      "Epoch 38/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0386 - acc: 0.9872 - val_loss: 0.0674 - val_acc: 0.9803\n",
      "Epoch 39/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0375 - acc: 0.9872 - val_loss: 0.0670 - val_acc: 0.9803\n",
      "Epoch 40/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0369 - acc: 0.9877 - val_loss: 0.0715 - val_acc: 0.9783\n",
      "Epoch 41/110\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0367 - acc: 0.9891 - val_loss: 0.0709 - val_acc: 0.9763\n",
      "Epoch 42/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0360 - acc: 0.9877 - val_loss: 0.0723 - val_acc: 0.9783\n",
      "Epoch 43/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0350 - acc: 0.9887 - val_loss: 0.0730 - val_acc: 0.9803\n",
      "Epoch 44/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0345 - acc: 0.9887 - val_loss: 0.0735 - val_acc: 0.9783\n",
      "Epoch 45/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0331 - acc: 0.9896 - val_loss: 0.0708 - val_acc: 0.9783\n",
      "Epoch 46/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0322 - acc: 0.9891 - val_loss: 0.0717 - val_acc: 0.9822\n",
      "Epoch 47/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0330 - acc: 0.9872 - val_loss: 0.0747 - val_acc: 0.9763\n",
      "Epoch 48/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0309 - acc: 0.9906 - val_loss: 0.0717 - val_acc: 0.9803\n",
      "Epoch 49/110\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0301 - acc: 0.9901 - val_loss: 0.0727 - val_acc: 0.9783\n",
      "Epoch 50/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0301 - acc: 0.9911 - val_loss: 0.0736 - val_acc: 0.9803\n",
      "Epoch 51/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0302 - acc: 0.9896 - val_loss: 0.0726 - val_acc: 0.9803\n",
      "Epoch 52/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0288 - acc: 0.9916 - val_loss: 0.0748 - val_acc: 0.9803\n",
      "Epoch 53/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0282 - acc: 0.9911 - val_loss: 0.0726 - val_acc: 0.9803\n",
      "Epoch 54/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0289 - acc: 0.9896 - val_loss: 0.0747 - val_acc: 0.9783\n",
      "Epoch 55/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0271 - acc: 0.9901 - val_loss: 0.0772 - val_acc: 0.9783\n",
      "Epoch 56/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0265 - acc: 0.9926 - val_loss: 0.0753 - val_acc: 0.9803\n",
      "Epoch 57/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0250 - acc: 0.9931 - val_loss: 0.0768 - val_acc: 0.9783\n",
      "Epoch 58/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0255 - acc: 0.9916 - val_loss: 0.0767 - val_acc: 0.9803\n",
      "Epoch 59/110\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0248 - acc: 0.9931 - val_loss: 0.0776 - val_acc: 0.9783\n",
      "Epoch 60/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0241 - acc: 0.9926 - val_loss: 0.0764 - val_acc: 0.9803\n",
      "Epoch 61/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0236 - acc: 0.9931 - val_loss: 0.0801 - val_acc: 0.9822\n",
      "Epoch 62/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0230 - acc: 0.9936 - val_loss: 0.0795 - val_acc: 0.9803\n",
      "Epoch 63/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0224 - acc: 0.9936 - val_loss: 0.0793 - val_acc: 0.9803\n",
      "Epoch 64/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0225 - acc: 0.9936 - val_loss: 0.0837 - val_acc: 0.9783\n",
      "Epoch 65/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0214 - acc: 0.9936 - val_loss: 0.0797 - val_acc: 0.9803\n",
      "Epoch 66/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0213 - acc: 0.9941 - val_loss: 0.0801 - val_acc: 0.9803\n",
      "Epoch 67/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0207 - acc: 0.9941 - val_loss: 0.0815 - val_acc: 0.9803\n",
      "Epoch 68/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0202 - acc: 0.9946 - val_loss: 0.0807 - val_acc: 0.9803\n",
      "Epoch 69/110\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0201 - acc: 0.9941 - val_loss: 0.0825 - val_acc: 0.9803\n",
      "Epoch 70/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0213 - acc: 0.9926 - val_loss: 0.0775 - val_acc: 0.9803\n",
      "Epoch 71/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0216 - acc: 0.9936 - val_loss: 0.0799 - val_acc: 0.9783\n",
      "Epoch 72/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0192 - acc: 0.9946 - val_loss: 0.0752 - val_acc: 0.9783\n",
      "Epoch 73/110\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0178 - acc: 0.9956 - val_loss: 0.0806 - val_acc: 0.9763\n",
      "Epoch 74/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0180 - acc: 0.9946 - val_loss: 0.0787 - val_acc: 0.9803\n",
      "Epoch 75/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0170 - acc: 0.9951 - val_loss: 0.0812 - val_acc: 0.9783\n",
      "Epoch 76/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0171 - acc: 0.9951 - val_loss: 0.0838 - val_acc: 0.9763\n",
      "Epoch 77/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0160 - acc: 0.9961 - val_loss: 0.0827 - val_acc: 0.9803\n",
      "Epoch 78/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0153 - acc: 0.9965 - val_loss: 0.0853 - val_acc: 0.9783\n",
      "Epoch 79/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0152 - acc: 0.9956 - val_loss: 0.0883 - val_acc: 0.9783\n",
      "Epoch 80/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0147 - acc: 0.9961 - val_loss: 0.0875 - val_acc: 0.9763\n",
      "Epoch 81/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0151 - acc: 0.9961 - val_loss: 0.0859 - val_acc: 0.9763\n",
      "Epoch 82/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0142 - acc: 0.9970 - val_loss: 0.0887 - val_acc: 0.9763\n",
      "Epoch 83/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0139 - acc: 0.9975 - val_loss: 0.0876 - val_acc: 0.9763\n",
      "Epoch 84/110\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0140 - acc: 0.9956 - val_loss: 0.0901 - val_acc: 0.9783\n",
      "Epoch 85/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0132 - acc: 0.9965 - val_loss: 0.0906 - val_acc: 0.9763\n",
      "Epoch 86/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0126 - acc: 0.9980 - val_loss: 0.0916 - val_acc: 0.9763\n",
      "Epoch 87/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0121 - acc: 0.9980 - val_loss: 0.0958 - val_acc: 0.9783\n",
      "Epoch 88/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0124 - acc: 0.9975 - val_loss: 0.0917 - val_acc: 0.9763\n",
      "Epoch 89/110\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0121 - acc: 0.9980 - val_loss: 0.0926 - val_acc: 0.9783\n",
      "Epoch 90/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0115 - acc: 0.9980 - val_loss: 0.0947 - val_acc: 0.9783\n",
      "Epoch 91/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0119 - acc: 0.9970 - val_loss: 0.0927 - val_acc: 0.9783\n",
      "Epoch 92/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0111 - acc: 0.9975 - val_loss: 0.0963 - val_acc: 0.9783\n",
      "Epoch 93/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0105 - acc: 0.9985 - val_loss: 0.0979 - val_acc: 0.9783\n",
      "Epoch 94/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0107 - acc: 0.9975 - val_loss: 0.1038 - val_acc: 0.9763\n",
      "Epoch 95/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0102 - acc: 0.9985 - val_loss: 0.0975 - val_acc: 0.9783\n",
      "Epoch 96/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0097 - acc: 0.9985 - val_loss: 0.1005 - val_acc: 0.9763\n",
      "Epoch 97/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0096 - acc: 0.9985 - val_loss: 0.1025 - val_acc: 0.9783\n",
      "Epoch 98/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0097 - acc: 0.9985 - val_loss: 0.0997 - val_acc: 0.9783\n",
      "Epoch 99/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0101 - acc: 0.9990 - val_loss: 0.1009 - val_acc: 0.9783\n",
      "Epoch 100/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0090 - acc: 0.9985 - val_loss: 0.1076 - val_acc: 0.9783\n",
      "Epoch 101/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0088 - acc: 0.9985 - val_loss: 0.1054 - val_acc: 0.9783\n",
      "Epoch 102/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0085 - acc: 0.9990 - val_loss: 0.1049 - val_acc: 0.9783\n",
      "Epoch 103/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0081 - acc: 0.9985 - val_loss: 0.1068 - val_acc: 0.9783\n",
      "Epoch 104/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0080 - acc: 0.9990 - val_loss: 0.1126 - val_acc: 0.9783\n",
      "Epoch 105/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0078 - acc: 0.9985 - val_loss: 0.1098 - val_acc: 0.9783\n",
      "Epoch 106/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0086 - acc: 0.9985 - val_loss: 0.1095 - val_acc: 0.9783\n",
      "Epoch 107/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0083 - acc: 0.9990 - val_loss: 0.1115 - val_acc: 0.9783\n",
      "Epoch 108/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0074 - acc: 0.9995 - val_loss: 0.1118 - val_acc: 0.9783\n",
      "Epoch 109/110\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0073 - acc: 0.9990 - val_loss: 0.1157 - val_acc: 0.9763\n",
      "Epoch 110/110\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0068 - acc: 0.9990 - val_loss: 0.1147 - val_acc: 0.9783\n",
      "Wall time: 9.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "deepfm = DeepFM(linear_feature_columns=linear_feature,\n",
    "                dnn_feature_columns=deep_feature,\n",
    "                dnn_hidden_units=(32,32),\n",
    "                seed=2020,\n",
    "                task='binary')\n",
    "deepfm.compile('adam', loss='BinaryCrossentropy' , metrics='acc')\n",
    "\n",
    "# 查看可以使用什么loss\n",
    "# import tensorflow as tf\n",
    "# tf.keras.losses??\n",
    "\n",
    "import multiprocessing\n",
    "history = deepfm.fit(train_data, y_train, batch_size=64, epochs=110, verbose=True, validation_split=0.2, use_multiprocessing=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9870    0.9870    0.9870       308\n",
      "           1     0.9877    0.9877    0.9877       326\n",
      "\n",
      "    accuracy                         0.9874       634\n",
      "   macro avg     0.9874    0.9874    0.9874       634\n",
      "weighted avg     0.9874    0.9874    0.9874       634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = deepfm.predict(test_data)\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, np.where(pred>0.5, 1,0), digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
