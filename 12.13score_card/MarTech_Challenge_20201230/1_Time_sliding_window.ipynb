{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  #\n",
    "from datetime import datetime, date, timedelta\n",
    "from scipy.stats import skew  # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV,Ridge,Lasso,ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.svm import SVR, LinearSVC\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from itertools import product\n",
    "import datetime as dt\n",
    "import calendar\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "# 引入中文字体\n",
    "from matplotlib.font_manager import FontProperties\n",
    "myfont = FontProperties(fname=\"/home/aistudio/NotoSansCJKsc-Light.otf\", size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/'\n",
    "train = pd.read_csv(PATH + 'train.csv')\n",
    "# train = pd.read_csv('./data/data19383/train.csv', usecols=[2, 3, 4, 6, 7, 18])\n",
    "# set index to ID to avoid droping it later\n",
    "# 把测试集的id列作为索引，防止误删\n",
    "test  = pd.read_csv(PATH + 'submission.csv').set_index('customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集使用内容 510.40096282958984 MB\n",
      "测试集使用内存 24.200225830078125 MB\n"
     ]
    }
   ],
   "source": [
    "# 对于特别大的文件，我们需要做一些内存检查\n",
    "mem_train = train.memory_usage(index=True).sum()\n",
    "mem_test=test.memory_usage(index=True).sum()\n",
    "print(u\"训练集使用内容 \"+ str(mem_train/ 1024**2)+\" MB\")\n",
    "print(u\"测试集使用内存 \"+ str(mem_test/ 1024**2)+\" MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @from: https://www.kaggle.com/arjanso/reducing-dataframe-memory-size-by-65/code\n",
    "# @liscense: Apache 2.0\n",
    "# @author: weijian\n",
    "def reduce_mem_usage(props):\n",
    "    # 计算当前内存\n",
    "    start_mem_usg = props.memory_usage().sum() / 1024 ** 2\n",
    "    print(\"Memory usage of the dataframe is :\", start_mem_usg, \"MB\")\n",
    "    \n",
    "    # 哪些列包含空值，空值用-999填充。why：因为np.nan当做float处理\n",
    "    NAlist = []\n",
    "    for col in props.columns:\n",
    "        # 这里只过滤了objectd格式，如果你的代码中还包含其他类型，请一并过滤\n",
    "        if (props[col].dtypes != object):\n",
    "            \n",
    "            # print(\"**************************\")\n",
    "            # print(\"columns: \", col)\n",
    "            # print(\"dtype before\", props[col].dtype)\n",
    "            \n",
    "            # 判断是否是int类型\n",
    "            isInt = False\n",
    "            mmax = props[col].max()\n",
    "            mmin = props[col].min()\n",
    "            \n",
    "            # Integer does not support NA, therefore Na needs to be filled\n",
    "            if not np.isfinite(props[col]).all():\n",
    "                NAlist.append(col)\n",
    "                props[col].fillna(-999, inplace=True) # 用-999填充\n",
    "                \n",
    "            # test if column can be converted to an integer\n",
    "            asint = props[col].fillna(0).astype(np.int64)\n",
    "            result = np.fabs(props[col] - asint)\n",
    "            result = result.sum()\n",
    "            if result < 0.01: # 绝对误差和小于0.01认为可以转换的，要根据task修改\n",
    "                isInt = True\n",
    "            \n",
    "            # make interger / unsigned Integer datatypes\n",
    "            if isInt:\n",
    "                if mmin >= 0: # 最小值大于0，转换成无符号整型\n",
    "                    if mmax <= 255:\n",
    "                        props[col] = props[col].astype(np.uint8)\n",
    "                    elif mmax <= 65535:\n",
    "                        props[col] = props[col].astype(np.uint16)\n",
    "                    elif mmax <= 4294967295:\n",
    "                        props[col] = props[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        props[col] = props[col].astype(np.uint64)\n",
    "                else: # 转换成有符号整型\n",
    "                    if mmin > np.iinfo(np.int8).min and mmax < np.iinfo(np.int8).max:\n",
    "                        props[col] = props[col].astype(np.int8)\n",
    "                    elif mmin > np.iinfo(np.int16).min and mmax < np.iinfo(np.int16).max:\n",
    "                        props[col] = props[col].astype(np.int16)\n",
    "                    elif mmin > np.iinfo(np.int32).min and mmax < np.iinfo(np.int32).max:\n",
    "                        props[col] = props[col].astype(np.int32)\n",
    "                    elif mmin > np.iinfo(np.int64).min and mmax < np.iinfo(np.int64).max:\n",
    "                        props[col] = props[col].astype(np.int64)  \n",
    "            else: # 注意：这里对于float都转换成float16，需要根据你的情况自己更改\n",
    "                props[col] = props[col].astype(np.float16)\n",
    "            \n",
    "            # print(\"dtype after\", props[col].dtype)\n",
    "            # print(\"********************************\")\n",
    "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "    mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    return props, NAlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集使用内容 349.8006982803345 MB\n",
      "测试集使用内存 24.200225830078125 MB\n"
     ]
    }
   ],
   "source": [
    "# 处理id字段\n",
    "train['order_detail_id'] = train['order_detail_id'].astype(np.uint32)\n",
    "train['order_id'] = train['order_id'].astype(np.uint32)\n",
    "train['customer_id'] = train['customer_id'].astype(np.uint32)\n",
    "train['goods_id'] = train['goods_id'].astype(np.uint32)\n",
    "train['goods_class_id'] = train['goods_class_id'].astype(np.uint32)\n",
    "train['member_id'] = train['member_id'].astype(np.uint32)\n",
    "# 处理状态字段，这里同时处理空值，将空值置为0\n",
    "train['order_status'] = train['order_status'].astype(np.uint8)\n",
    "train['goods_has_discount'] = train['goods_has_discount'].astype(np.uint8)\n",
    "train[\"is_member_actived\"].fillna(0, inplace=True)\n",
    "train[\"is_member_actived\"]=train[\"is_member_actived\"].astype(np.int8)\n",
    "train[\"member_status\"].fillna(0, inplace=True)\n",
    "train[\"member_status\"]=train[\"member_status\"].astype(np.int8)\n",
    "train[\"customer_gender\"].fillna(0, inplace=True)\n",
    "train[\"customer_gender\"]=train[\"customer_gender\"].astype(np.int8)\n",
    "train['is_customer_rate'] = train['is_customer_rate'].astype(np.uint8)\n",
    "train['order_detail_status'] = train['order_detail_status'].astype(np.uint8)\n",
    "# 处理日期\n",
    "train['goods_list_time']=pd.to_datetime(train['goods_list_time'],format=\"%Y-%m-%d\")\n",
    "train['order_pay_time']=pd.to_datetime(train['order_pay_time'],format=\"%Y-%m-%d\")\n",
    "train['goods_delist_time']=pd.to_datetime(train['goods_delist_time'],format=\"%Y-%m-%d\")\n",
    "# 检查内存使用\n",
    "mem_train = train.memory_usage(index=True).sum()\n",
    "mem_test=test.memory_usage(index=True).sum()\n",
    "print(u\"训练集使用内容 \"+ str(mem_train/ 1024**2)+\" MB\")\n",
    "print(u\"测试集使用内存 \"+ str(mem_test/ 1024**2)+\" MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['customer_city_id'] = LabelEncoder().fit_transform(train['customer_city'].astype(str))\n",
    "train['customer_province_id'] = LabelEncoder().fit_transform(train['customer_province'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 纯时间序列滑窗\n",
    "训练集和测试集构造思路：\n",
    "- 训练集\n",
    "\t- 训练日期截止分别为2013.6.6、2013.6.20、2013.7.1、2013.7.15\n",
    "\t- 标签为训练截止日期开始的30天有没有下过单\n",
    "\t- 标签通过切片的形式构造\n",
    "    - 把4个部分训练集拼起来\n",
    "- 验证集\n",
    "\t- 验证数据到2013.8.1\n",
    "\t- 标签为2013.8.1开始的30天有没有下过单\n",
    "\t- 标签时间2013.8.1-2013.8.30\n",
    "- 测试集\n",
    "\t- 测试数据到2013.8.31\n",
    "\t- 没有标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_detail_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_total_num</th>\n",
       "      <th>order_amount</th>\n",
       "      <th>order_total_payment</th>\n",
       "      <th>order_total_discount</th>\n",
       "      <th>order_pay_time</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_count</th>\n",
       "      <th>is_customer_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>is_member_actived</th>\n",
       "      <th>goods_id</th>\n",
       "      <th>goods_class_id</th>\n",
       "      <th>goods_price</th>\n",
       "      <th>goods_status</th>\n",
       "      <th>goods_has_discount</th>\n",
       "      <th>goods_list_time</th>\n",
       "      <th>goods_delist_time</th>\n",
       "      <th>customer_city_id</th>\n",
       "      <th>customer_province_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>239.9</td>\n",
       "      <td>96.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-11-01 00:10:56</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>54.909289</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-25 11:08:07</td>\n",
       "      <td>2014-11-01 11:08:07</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001530</td>\n",
       "      <td>1001327</td>\n",
       "      <td>2.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>96.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-08-31 23:14:42</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1953</td>\n",
       "      <td>1953</td>\n",
       "      <td>45.961352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-08-28 17:27:50</td>\n",
       "      <td>2013-09-01 00:38:17</td>\n",
       "      <td>322</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001531</td>\n",
       "      <td>1001327</td>\n",
       "      <td>2.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>96.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-08-31 23:14:42</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1083</td>\n",
       "      <td>1083</td>\n",
       "      <td>53.035439</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-29 18:21:05</td>\n",
       "      <td>2014-11-05 18:21:05</td>\n",
       "      <td>322</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001532</td>\n",
       "      <td>1001328</td>\n",
       "      <td>3.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>89.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-08-31 22:06:35</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1013</td>\n",
       "      <td>1013</td>\n",
       "      <td>46.046917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-25 11:00:00</td>\n",
       "      <td>2014-11-01 11:00:00</td>\n",
       "      <td>185</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001533</td>\n",
       "      <td>1001329</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.9</td>\n",
       "      <td>65.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-08-31 21:33:36</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1628</td>\n",
       "      <td>1628</td>\n",
       "      <td>50.722161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-23 15:35:33</td>\n",
       "      <td>2014-10-30 15:35:33</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_detail_id  order_id  order_total_num  order_amount  \\\n",
       "0          1000000   1000000              1.0         239.9   \n",
       "1          1001530   1001327              2.0         288.0   \n",
       "2          1001531   1001327              2.0         288.0   \n",
       "3          1001532   1001328              3.0         180.0   \n",
       "4          1001533   1001329              1.0         159.9   \n",
       "\n",
       "   order_total_payment  order_total_discount      order_pay_time  \\\n",
       "0                 96.9                   0.0 2012-11-01 00:10:56   \n",
       "1                 96.9                   0.0 2013-08-31 23:14:42   \n",
       "2                 96.9                   0.0 2013-08-31 23:14:42   \n",
       "3                 89.7                   0.0 2013-08-31 22:06:35   \n",
       "4                 65.9                   0.0 2013-08-31 21:33:36   \n",
       "\n",
       "   order_status  order_count  is_customer_rate  ...  is_member_actived  \\\n",
       "0             6          1.0                 0  ...                  0   \n",
       "1             6          2.0                 0  ...                  0   \n",
       "2             6          2.0                 0  ...                  0   \n",
       "3             6          1.0                 0  ...                  0   \n",
       "4             6          1.0                 0  ...                  0   \n",
       "\n",
       "   goods_id  goods_class_id  goods_price  goods_status goods_has_discount  \\\n",
       "0       998             998    54.909289           1.0                  0   \n",
       "1      1953            1953    45.961352           0.0                  1   \n",
       "2      1083            1083    53.035439           1.0                  0   \n",
       "3      1013            1013    46.046917           1.0                  1   \n",
       "4      1628            1628    50.722161           1.0                  0   \n",
       "\n",
       "      goods_list_time   goods_delist_time  customer_city_id  \\\n",
       "0 2014-10-25 11:08:07 2014-11-01 11:08:07                53   \n",
       "1 2013-08-28 17:27:50 2013-09-01 00:38:17               322   \n",
       "2 2014-10-29 18:21:05 2014-11-05 18:21:05               322   \n",
       "3 2014-10-25 11:00:00 2014-11-01 11:00:00               185   \n",
       "4 2014-10-23 15:35:33 2014-10-30 15:35:33                53   \n",
       "\n",
       "   customer_province_id  \n",
       "0                     4  \n",
       "1                     3  \n",
       "2                     3  \n",
       "3                    20  \n",
       "4                     4  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1585986"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['customer_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1585986 entries, 1000000 to 2826574\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count    Dtype  \n",
      "---  ------  --------------    -----  \n",
      " 0   result  1585986 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 24.2 MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000000</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000014</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000034</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000046</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000048</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             result\n",
       "customer_id        \n",
       "1000000         0.0\n",
       "1000014         0.0\n",
       "1000034         0.0\n",
       "1000046         0.0\n",
       "1000048         0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的比对可以看出，这里要预测的是全体用户未来一个月的购买情况，训练集和测试集的`id`完全重合，没有需要特别处理的地方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造时间滑窗特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "时间滑窗构造\n",
    "- [已完成] 考虑到按周、按月的订单规律性变化，时间滑窗往往是7和30的倍数\n",
    "- [已完成] 一般选取的特征是滑窗中的基本统计值，最大、最小、均值、中位数、求和等等\n",
    "- [未完成] 节假日信息、影响周期的时间滑窗整合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将用户下单金额按天进行汇总\n",
    "# df = train[train.order_status<101][train.order_pay_time>'2013-02-01']\n",
    "df = train[train.order_pay_time>'2013-02-01']\n",
    "df['date'] = pd.DatetimeIndex(df['order_pay_time']).date\n",
    "df_payment = df[['customer_id','date','order_total_payment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685471"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_payment['customer_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，成功交易的客户数量不等于全部客户数量，说明有相当一部分客户虽然下过单，但是没有成功的订单，那么这些客户自然应当算在训练集之外。\n",
    "数据合并时，由于`test.csv`中，已经设置了默认0值，只需要和训练后的预测标签做一个`left join`就可以了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_payment = df_payment.groupby(['date','customer_id']).agg({'order_total_payment': ['sum']})\n",
    "df_payment.columns = ['day_total_payment']\n",
    "df_payment.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_payment = df_payment.set_index(\n",
    "    [\"customer_id\", \"date\"])[[\"day_total_payment\"]].unstack(level=-1).fillna(0)\n",
    "df_payment.columns = df_payment.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>date</th>\n",
       "      <th>2013-02-01</th>\n",
       "      <th>2013-02-02</th>\n",
       "      <th>2013-02-03</th>\n",
       "      <th>2013-02-04</th>\n",
       "      <th>2013-02-05</th>\n",
       "      <th>2013-02-06</th>\n",
       "      <th>2013-02-07</th>\n",
       "      <th>2013-02-08</th>\n",
       "      <th>2013-02-09</th>\n",
       "      <th>2013-02-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2013-08-22</th>\n",
       "      <th>2013-08-23</th>\n",
       "      <th>2013-08-24</th>\n",
       "      <th>2013-08-25</th>\n",
       "      <th>2013-08-26</th>\n",
       "      <th>2013-08-27</th>\n",
       "      <th>2013-08-28</th>\n",
       "      <th>2013-08-29</th>\n",
       "      <th>2013-08-30</th>\n",
       "      <th>2013-08-31</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000014</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000034</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000046</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000069</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000105</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date         2013-02-01  2013-02-02  2013-02-03  2013-02-04  2013-02-05  \\\n",
       "customer_id                                                               \n",
       "1000014             0.0         0.0         0.0         0.0         0.0   \n",
       "1000034             0.0         0.0         0.0         0.0         0.0   \n",
       "1000046             0.0         0.0         0.0         0.0         0.0   \n",
       "1000069             0.0         0.0         0.0         0.0         0.0   \n",
       "1000105             0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "date         2013-02-06  2013-02-07  2013-02-08  2013-02-09  2013-02-10  ...  \\\n",
       "customer_id                                                              ...   \n",
       "1000014             0.0         0.0         0.0         0.0         0.0  ...   \n",
       "1000034             0.0         0.0         0.0         0.0         0.0  ...   \n",
       "1000046             0.0         0.0         0.0         0.0         0.0  ...   \n",
       "1000069             0.0         0.0         0.0         0.0         0.0  ...   \n",
       "1000105             0.0         0.0         0.0         0.0         0.0  ...   \n",
       "\n",
       "date         2013-08-22  2013-08-23  2013-08-24  2013-08-25  2013-08-26  \\\n",
       "customer_id                                                               \n",
       "1000014             0.0         0.0         0.0         0.0         0.0   \n",
       "1000034             0.0         0.0         0.0         0.0         0.0   \n",
       "1000046             0.0         0.0         0.0         0.0         0.0   \n",
       "1000069             0.0         0.0         0.0         0.0         0.0   \n",
       "1000105             0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "date         2013-08-27  2013-08-28  2013-08-29  2013-08-30  2013-08-31  \n",
       "customer_id                                                              \n",
       "1000014             0.0         0.0         0.0         0.0         0.0  \n",
       "1000034             0.0         0.0         0.0         0.0         0.0  \n",
       "1000046             0.0         0.0         0.0         0.0         0.0  \n",
       "1000069             0.0         0.0         0.0         0.0         0.0  \n",
       "1000105             0.0         0.0         0.0         0.0         0.0  \n",
       "\n",
       "[5 rows x 212 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_payment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_goods = df[['customer_id','date','order_total_num']]\n",
    "df_goods = df_goods.groupby(['date','customer_id']).agg({'order_total_num': ['sum']})\n",
    "df_goods.columns = ['day_total_num']\n",
    "df_goods.reset_index(inplace=True)\n",
    "df_goods = df_goods.set_index(\n",
    "    [\"customer_id\", \"date\"])[[\"day_total_num\"]].unstack(level=-1).fillna(0)\n",
    "df_goods.columns = df_goods.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是一个时间滑窗函数，获得dt之前minus天以来periods的dataframe，以便进一步计算\n",
    "def get_timespan(df, dt, minus, periods, freq='D'):\n",
    "    return df[pd.date_range(dt - timedelta(days=minus), periods=periods, freq=freq)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 构造dataset这里有个取巧的地方，因为要预测的9月份除了开学季以外不是非常特殊的月份，因此主要考虑近期的因素，数据集的开始时间也是2月1日，尽量避免了双十一、元旦假期的影响，当然春节假期继续保留。同时，构造数据集的时候保留了customer_id，主要为了与其它特征做整合。\n",
    "2. 通过一个函数整合付款金额和商品数量的时间滑窗，主要是因为分开做到时候合并占用内存更大，并且函数最后在返回值处做了内存优化，用时间代价尽可能避免内存溢出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df_payment, df_goods, t2018, is_train=True):\n",
    "    X = {}\n",
    "    # 整合用户id\n",
    "    tmp = df_payment.reset_index()\n",
    "    X['customer_id'] = tmp['customer_id']\n",
    "    # 消费特征\n",
    "    print('Preparing payment feature...')\n",
    "    for i in [7,14,30,49,60,91,120]:\n",
    "        tmp_1 = get_timespan(df_payment, t2018, i, i)\n",
    "        # X['diff_%s_mean' % i] = tmp_1.diff(axis=1).mean(axis=1).values\n",
    "        # X['mean_%s_decay' % i] = (tmp_1 * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values\n",
    "        X['mean_%s' % i] = tmp_1.mean(axis=1).values\n",
    "        X['median_%s' % i] = tmp_1.median(axis=1).values\n",
    "        # X['min_%s' % i] = tmp_1.min(axis=1).values\n",
    "        X['max_%s' % i] = tmp_1.max(axis=1).values\n",
    "        # X['std_%s' % i] = tmp_1.std(axis=1).values\n",
    "        X['sum_%s' % i] = tmp_1.sum(axis=1).values\n",
    "\n",
    "        tmp_2 = get_timespan(df_payment, t2018 + timedelta(weeks=-1), i, i)\n",
    "        # X['diff_%s_mean_2' % i] = tmp_2.diff(axis=1).mean(axis=1).values\n",
    "        # X['mean_%s_decay_2' % i] = (tmp_2 * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values\n",
    "        X['mean_%s_2' % i] = tmp_2.mean(axis=1).values\n",
    "        X['median_%s_2' % i] = tmp_2.median(axis=1).values\n",
    "        # X['min_%s_2' % i] = tmp_2.min(axis=1).values\n",
    "        X['max_%s_2' % i] = tmp_2.max(axis=1).values\n",
    "        # X['std_%s_2' % i] = tmp_2.std(axis=1).values\n",
    "\n",
    "        tmp_3 = get_timespan(df_payment, t2018, i, i)\n",
    "        X['has_sales_days_in_last_%s' % i] = (tmp_3 != 0).sum(axis=1).values\n",
    "        X['last_has_sales_day_in_last_%s' % i] = i - ((tmp_3 != 0) * np.arange(i)).max(axis=1).values\n",
    "        X['first_has_sales_day_in_last_%s' % i] = ((tmp_3 != 0) * np.arange(i, 0, -1)).max(axis=1).values\n",
    "\n",
    "    # 对此处进行微调，主要考虑近期因素\n",
    "    for i in range(1, 4):\n",
    "        X['day_%s_2018' % i] = get_timespan(df_payment, t2018, i*30, 30).sum(axis=1).values\n",
    "\n",
    "    for i in range(7):\n",
    "        X['mean_4_dow{}_2013'.format(i)] = get_timespan(df_payment, t2018, 56-i*2, 4, freq='14D').mean(axis=1).values\n",
    "        # X['mean_20_dow{}_2013'.format(i)] = get_timespan(df, t2018, 140-i, 20, freq='7D').mean(axis=1).values\n",
    "        X['mean_20_dow{}_2013'.format(i)] = get_timespan(df_payment, t2018, 140-i*2, 10, freq='14D').mean(axis=1).values\n",
    "    \n",
    "    # 商品数量特征，这里故意把时间和消费特征错开，提高时间滑窗的覆盖面\n",
    "    print('Preparing num feature...')\n",
    "    for i in [3,21,35,49,70,84,105]:\n",
    "            tmp_1 = get_timespan(df_goods, t2018, i, i)\n",
    "            # X['goods_diff_%s_mean' % i] = tmp_1.diff(axis=1).mean(axis=1).values\n",
    "            # X['goods_mean_%s_decay' % i] = (tmp_1 * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values\n",
    "            X['goods_mean_%s' % i] = tmp_1.mean(axis=1).values\n",
    "            X['goods_median_%s' % i] = tmp_1.median(axis=1).values\n",
    "            # X['goods_min_%s' % i] = tmp_1.min(axis=1).values\n",
    "            X['goods_max_%s' % i] = tmp_1.max(axis=1).values\n",
    "            # X['goods_std_%s' % i] = tmp_1.std(axis=1).values\n",
    "            X['goods_sum_%s' % i] = tmp_1.sum(axis=1).values\n",
    "    \n",
    "            tmp_2 = get_timespan(df_goods, t2018 + timedelta(weeks=-1), i, i)\n",
    "            # X['goods_diff_%s_mean_2' % i] = tmp_2.diff(axis=1).mean(axis=1).values\n",
    "            # X['goods_mean_%s_decay_2' % i] = (tmp_2 * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values\n",
    "            X['goods_mean_%s_2' % i] = tmp_2.mean(axis=1).values\n",
    "            X['goods_median_%s_2' % i] = tmp_2.median(axis=1).values\n",
    "            # X['goods_min_%s_2' % i] = tmp_2.min(axis=1).values\n",
    "            X['goods_max_%s_2' % i] = tmp_2.max(axis=1).values\n",
    "            X['goods_sum_%s_2' % i] = tmp_2.sum(axis=1).values\n",
    "    \n",
    "            tmp_3 = get_timespan(df_goods, t2018, i, i)\n",
    "            X['goods_has_sales_days_in_last_%s' % i] = (tmp_3 > 0).sum(axis=1).values\n",
    "            X['goods_last_has_sales_day_in_last_%s' % i] = i - ((tmp_3 > 0) * np.arange(i)).max(axis=1).values\n",
    "            X['goods_first_has_sales_day_in_last_%s' % i] = ((tmp_3 > 0) * np.arange(i, 0, -1)).max(axis=1).values\n",
    "\n",
    "\n",
    "    # 对此处进行微调，主要考虑近期因素\n",
    "    for i in range(1, 4):\n",
    "        X['goods_day_%s_2018' % i] = get_timespan(df_goods, t2018, i*28, 28).sum(axis=1).values\n",
    "\n",
    "    for i in range(7):\n",
    "        X['goods_mean_4_dow{}_2013'.format(i)] = get_timespan(df_goods, t2018, 56-i*2, 4, freq='14D').mean(axis=1).values\n",
    "        # X['mean_20_dow{}_2013'.format(i   = get_timespan(df, t2018, 140-i, 20, freq='7D').mean(axis=1).values\n",
    "        X['goods_mean_20_dow{}_2013'.format(i)] = get_timespan(df_goods, t2018, 140-i*2, 10, freq='14D').mean(axis=1).values\n",
    "\n",
    "    X = pd.DataFrame(X)\n",
    "    \n",
    "    reduce_mem_usage(X)\n",
    "    \n",
    "    if is_train:\n",
    "        # 这样转换之后，打标签直接用numpy切片就可以了\n",
    "        # 当然这里前提是确认付款总额没有负数的问题\n",
    "        y = df_goods[pd.date_range(t2018, periods=30)].max(axis=1).values\n",
    "        y[y > 0] = 1\n",
    "        return X, y\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成滑窗数据\n",
    "此处对内存占用要求非常高，尽量分步操作避免crash，即使如此，内存溢出仍然频繁出现，通过下面的办法进一步压缩数据集大小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成训练集\n",
    "对此处进行优化，把训练集不曾涉及到的新增用户剔除，也就是说，模型研究的是已有用户的购买行为变化趋势。如果一个用户在8月中旬才第一次下单，那么就不会被放到训练集/验证集中，只会出现在测试集中。\n",
    "\n",
    "内存限制的情况下，训练集和验证集时间的选取会比较纠结，既要考虑月份，也要考虑星期。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_slides(train,df_part,begin,end,column):\n",
    "    # 将用户下单金额按天进行汇总\n",
    "    # df = train[train.order_status <= 6][train.order_pay_time > '2013-02-01']\n",
    "    df = train[train.order_pay_time > begin][train.order_pay_time < end]\n",
    "    df = pd.merge(df,df_part,how='inner')\n",
    "    df['date'] = pd.DatetimeIndex(df['order_pay_time']).date\n",
    "    df = df[['customer_id', 'date', column]]\n",
    "    df = df.groupby(['date', 'customer_id']).agg({column: ['sum']})\n",
    "    df.columns = ['day_' + column]\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.set_index(\n",
    "        [\"customer_id\", \"date\"])[['day_' + column]].unstack(level=-1).fillna(0)\n",
    "    df.columns = df.columns.get_level_values(1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part1\n",
    "2013.06.06之前的用户，在2013.06.06后30天的时间滑窗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_timespan(df_goods, date(2013, 8, 1), 120-7*2, 10, freq='14D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_0606 pred_start-5个月, pred_start\n",
    "# make_slides跨度范围时 pred_start-5个月，pred_start+30\n",
    "# prepare_dataset 传入的时pred_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing payment feature...\n",
      "Preparing num feature...\n",
      "Memory usage of the dataframe is : 976.3886108398438 MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  219.39694023132324  MB\n",
      "This is  22.470247788184285 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "df_0606 = train[train.order_pay_time > '2013-01-01'][train.order_pay_time <= '2013-06-06'][['customer_id']]\n",
    "# 删除重复行\n",
    "df_0606 = df_0606.drop_duplicates(['customer_id'])\n",
    "df_part1_partment = make_slides(train,df_0606,'2013-01-01','2013-07-06','order_total_payment')\n",
    "df_part1_goods = make_slides(train,df_0606,'2013-01-01','2013-07-06','order_total_num')\n",
    "X_part1, y_part1 = prepare_dataset(df_part1_partment, df_part1_goods, date(2013, 6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_part1.to_pickle('work/X_part1.pkl')\n",
    "np.save(\"work/y_part1.npy\", y_part1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_0606\n",
    "del df_part1_partment\n",
    "del df_part1_goods\n",
    "del X_part1\n",
    "del y_part1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part2\n",
    "2013.06.20之前的用户，在2013.06.20后30天的时间滑窗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing payment feature...\n",
      "Preparing num feature...\n",
      "Memory usage of the dataframe is : 970.6541137695312 MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  215.2195339202881  MB\n",
      "This is  22.17262883525872 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "df_0620 = train[train.order_pay_time > '2013-01-15'][train.order_pay_time <= '2013-06-20'][['customer_id']]\n",
    "# 删除重复行\n",
    "df_0620 = df_0620.drop_duplicates(['customer_id'])\n",
    "df_part2_partment = make_slides(train,df_0620,'2013-01-15','2013-07-20','order_total_payment')\n",
    "df_part2_goods = make_slides(train,df_0620,'2013-01-15','2013-07-20','order_total_num')\n",
    "X_part2, y_part2 = prepare_dataset(df_part2_partment, df_part2_goods, date(2013, 6, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_part2.to_pickle('work/X_part2.pkl')\n",
    "np.save(\"work/y_part2.npy\", y_part2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_0620\n",
    "del df_part2_partment\n",
    "del df_part2_goods\n",
    "del X_part2\n",
    "del y_part2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part3\n",
    "2013.07.01之前的用户，在2013.07.01后30天的时间滑窗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing payment feature...\n",
      "Preparing num feature...\n",
      "Memory usage of the dataframe is : 740.1360473632812 MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  165.20903396606445  MB\n",
      "This is  22.321441382921165 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "df_0701 = train[train.order_pay_time > '2013-01-26'][train.order_pay_time <= '2013-07-01'][['customer_id']]\n",
    "# 删除重复行\n",
    "df_0701 = df_0701.drop_duplicates(['customer_id'])\n",
    "df_part3_partment = make_slides(train,df_0701,'2013-01-26','2013-07-31','order_total_payment')\n",
    "df_part3_goods = make_slides(train,df_0701,'2013-01-26','2013-07-31','order_total_num')\n",
    "X_part3, y_part3 = prepare_dataset(df_part3_partment, df_part3_goods, date(2013, 7, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_part3.to_pickle('work/X_part3.pkl')\n",
    "np.save(\"work/y_part3.npy\", y_part3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_0701\n",
    "del df_part3_partment\n",
    "del df_part3_goods\n",
    "del X_part3\n",
    "del y_part3\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part4\n",
    "2013.07.15之前的用户，在2013.07.15后30天的时间滑窗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing payment feature...\n",
      "Preparing num feature...\n",
      "Memory usage of the dataframe is : 486.11602783203125 MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  107.06136322021484  MB\n",
      "This is  22.023829104686094 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "df_0715 = train[train.order_pay_time > '2013-02-10'][train.order_pay_time <= '2013-07-15'][['customer_id']]\n",
    "# 删除重复行\n",
    "df_0715 = df_0715.drop_duplicates(['customer_id'])\n",
    "df_part4_partment = make_slides(train,df_0715,'2013-02-10','2013-08-16','order_total_payment')\n",
    "df_part4_goods = make_slides(train,df_0715,'2013-02-10','2013-08-16','order_total_num')\n",
    "X_part4, y_part4 = prepare_dataset(df_part4_partment, df_part4_goods, date(2013, 7, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_part4.to_pickle('work/X_part4.pkl')\n",
    "np.save(\"work/y_part4.npy\", y_part4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_0715\n",
    "del df_part4_partment\n",
    "del df_part4_goods\n",
    "del X_part4\n",
    "del y_part4\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Train dataset...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing Train dataset...\")\n",
    "X_l, y_l = [], []\n",
    "X_part1 = pd.read_pickle('work/X_part1.pkl')\n",
    "y_part1 = np.load('work/y_part1.npy')\n",
    "X_l.append(X_part1)\n",
    "y_l.append(y_part1)\n",
    "X_part2 = pd.read_pickle('work/X_part2.pkl')\n",
    "y_part2 = np.load('work/y_part2.npy')\n",
    "X_l.append(X_part2)\n",
    "y_l.append(y_part2)\n",
    "X_part3 = pd.read_pickle('work/X_part3.pkl')\n",
    "y_part3 = np.load('work/y_part3.npy')\n",
    "X_l.append(X_part3)\n",
    "y_l.append(y_part3)\n",
    "X_part4 = pd.read_pickle('work/X_part4.pkl')\n",
    "y_part4 = np.load('work/y_part4.npy')\n",
    "X_l.append(X_part4)\n",
    "y_l.append(y_part4)\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "print('done!')\n",
    "del X_l\n",
    "del y_l\n",
    "del X_part1\n",
    "del y_part1\n",
    "del X_part2\n",
    "del y_part2\n",
    "del X_part3\n",
    "del y_part3\n",
    "del X_part4\n",
    "del y_part4\n",
    "gc.collect()\n",
    "X_train.to_pickle('work/X_train.pkl')\n",
    "np.save(\"work/y_train.npy\", y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成验证集\n",
    "2013.08.01之前的用户，在2013.08.01后30天的时间滑窗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Validation dataset...\n",
      "Preparing payment feature...\n",
      "Preparing num feature...\n",
      "Memory usage of the dataframe is : 518.7106323242188 MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  113.85399150848389  MB\n",
      "This is  21.949423129873256 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing Validation dataset...\")\n",
    "df_0801 = train[train.order_pay_time > '2013-03-01'][train.order_pay_time <= '2013-08-01'][['customer_id']]\n",
    "# 删除重复行\n",
    "df_0801 = df_0801.drop_duplicates(['customer_id'])\n",
    "df_part5_partment = make_slides(train,df_0801,'2013-03-01','2013-08-31','order_total_payment')\n",
    "df_part5_goods = make_slides(train,df_0801,'2013-03-01','2013-08-31','order_total_num')\n",
    "X_val, y_val = prepare_dataset(df_part5_partment, df_part5_goods, date(2013, 8, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.to_pickle('work/X_val.pkl')\n",
    "np.save(\"work/y_val.npy\", y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_0801\n",
    "del df_part5_partment\n",
    "del df_part5_goods\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing payment feature...\n",
      "Preparing num feature...\n",
      "Memory usage of the dataframe is : 620.6754760742188 MB\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  137.15829181671143  MB\n",
      "This is  22.098229606917865 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "df_0901 = train[train.order_pay_time > '2013-03-01'][train.order_pay_time < '2013-09-01'][['customer_id']]\n",
    "# 删除重复行\n",
    "df_0901 = df_0901.drop_duplicates(['customer_id'])\n",
    "df_test_partment = make_slides(train,df_0901,'2013-04-01','2013-09-01','order_total_payment')\n",
    "df_test_goods = make_slides(train,df_0901,'2013-04-01','2013-09-01','order_total_num')\n",
    "X_test = prepare_dataset(df_test_partment, df_test_goods, date(2013, 9, 1),is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_pickle('work/X_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，整合了用户id的消费时间滑窗就完整了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 小结：\n",
    "- 纯时间序列滑窗也可以直接用模型开始训练，但是效果并不太好。\n",
    "考虑到还有其它重要的数据维度，此时需要构建新的交叉特征。如用户X商品，用户X会员，用户X城市，用户X省份等，然后与时间滑窗数据整合。\n",
    "\n",
    "- 纯时间滑窗还有个问题，面对当前这个非常稀疏的数据集，浪费了大量的内存空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用户基本特征\n",
    "\n",
    "把地域、会员这些基本信息整合到训练数据中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_gender</th>\n",
       "      <th>customer_province_id</th>\n",
       "      <th>customer_city_id</th>\n",
       "      <th>is_member_actived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1001324</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>322</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1001325</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1001326</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1001327</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   member_id  customer_id  customer_gender  customer_province_id  \\\n",
       "0          0      1000000                0                     4   \n",
       "1          0      1001324                0                     3   \n",
       "3          0      1001325                0                    20   \n",
       "4          0      1001326                0                     4   \n",
       "5          0      1001327                0                     4   \n",
       "\n",
       "   customer_city_id  is_member_actived  \n",
       "0                53                  0  \n",
       "1               322                  0  \n",
       "3               185                  0  \n",
       "4                53                  0  \n",
       "5                53                  0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customer = train[['member_id','customer_id','customer_gender','customer_province_id','customer_city_id','is_member_actived']]\n",
    "# 删除重复行\n",
    "df_customer = df_customer.drop_duplicates(['customer_id'])\n",
    "df_customer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.merge(X_train,df_customer,how='left')\n",
    "X_val = pd.merge(X_val,df_customer,how='left')\n",
    "X_test = pd.merge(X_test,df_customer,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle('X_train.pkl')\n",
    "X_val.to_pickle('X_val.pkl')\n",
    "X_test.to_pickle('X_test.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
